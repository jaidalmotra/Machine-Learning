{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d652985",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.006675,
     "end_time": "2024-03-24T22:09:54.970491",
     "exception": false,
     "start_time": "2024-03-24T22:09:54.963816",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Welcome!**\n",
    "Welcome to this beginner-friendly notebook on Convolutional Neural Networks (CNNs). If you've ever wondered how computers can \"see\" and understand images, you're in the right place! In this notebook, we'll embark on a journey to demystify the world of CNNs and learn how to build a simple image classification model step by step.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://www.kaggle.com/static/images/site-logo.png\" alt=\"Kaggle Logo\">\n",
    "</div>\n",
    "\n",
    "## Objective\n",
    "Our goal in this notebook is to introduce you to the fundamental concepts of CNNs and guide you through the process of building your first image classification model. Don't worry if you're new to deep learning – we'll take it one step at a time, explaining each concept along the way.\n",
    "\n",
    "## Prerequisites\n",
    "To make the most out of this tutorial, you should have basic knowledge of Python and a curiosity to explore the world of machine learning. No prior experience with deep learning is required – we'll cover the essentials together.\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659d4956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T22:09:54.985613Z",
     "iopub.status.busy": "2024-03-24T22:09:54.985247Z",
     "iopub.status.idle": "2024-03-24T22:10:12.206479Z",
     "shell.execute_reply": "2024-03-24T22:10:12.205299Z"
    },
    "papermill": {
     "duration": 17.232216,
     "end_time": "2024-03-24T22:10:12.209155",
     "exception": false,
     "start_time": "2024-03-24T22:09:54.976939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 22:09:58.611886: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-24 22:09:58.612024: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-24 22:09:58.766359: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_sample_images\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e3dde",
   "metadata": {
    "papermill": {
     "duration": 0.007619,
     "end_time": "2024-03-24T22:10:12.223142",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.215523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **What is a neural network?**\n",
    "A neural network is a machine learning program, or model, that makes decisions in a manner similar to the human brain, by using processes that mimic the way biological neurons work together to identify phenomena, weigh options and arrive at conclusions.\n",
    "\n",
    "Every neural network consists of layers of nodes, or artificial neurons—an input layer, one or more hidden layers, and an output layer. Each node connects to others, and has its own associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.\n",
    "\n",
    "Neural networks are sometimes called artificial neural networks (ANNs) or simulated neural networks (SNNs). They are a subset of machine learning, and at the heart of deep learning models.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://lh4.googleusercontent.com/bHUcWaeVAzZA-sQLGNbO8lX__7eEvRJX7XB3RM8MQbT-bd9KSBDNzzjD83y3lnn0UbyYp_QzFXb7OETKgJMRc8X6ZRu6UCgI9VQzbeWr9l0ptv0OcY-n62URBsLfbu91YqnbXfnA\" alt=\"neural network\">\n",
    "</div>\n",
    "\n",
    "# How do neural networks work?\n",
    "Think of each individual node as its own linear regression model, composed of input data, weights, a bias (or threshold), and an output. The formula would look something like this:\n",
    "\n",
    "∑wixi + bias = w1x1 + w2x2 + w3x3 + bias\n",
    "\n",
    "output = f(x) = 1 if ∑w1x1 + b>= 0; 0 if ∑w1x1 + b < 0\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*SCz0aTETjTYC864Bqjt6Og.png\" alt=\"neural network\">\n",
    "</div>\n",
    "\n",
    "Once an input layer is determined, weights are assigned. These weights help determine the importance of any given variable, with larger ones contributing more significantly to the output compared to other inputs. All inputs are then multiplied by their respective weights and then summed. Afterward, the output is passed through an activation function, which determines the output. If that output exceeds a given threshold, it “fires” (or activates) the node, passing data to the next layer in the network. This results in the output of one node becoming in the input of the next node. This process of passing data from one layer to the next layer defines this neural network as a feedforward network.\n",
    "\n",
    "Ultimately, the goal is to minimize our cost function to ensure correctness of fit for any given observation. As the model adjusts its weights and bias, it uses the cost function and reinforcement learning to reach the point of convergence, or the local minimum. The process in which the algorithm adjusts its weights is through gradient descent, allowing the model to determine the direction to take to reduce errors (or minimize the cost function). With each training example, the parameters of the model adjust to gradually converge at the minimum. \n",
    "\n",
    "Most deep neural networks are feedforward, meaning they flow in one direction only, from input to output. However, you can also train your model through backpropagation; that is, move in the opposite direction from output to input. Backpropagation allows us to calculate and attribute the error associated with each neuron, allowing us to adjust and fit the parameters of the model(s) appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e1174b",
   "metadata": {
    "papermill": {
     "duration": 0.005944,
     "end_time": "2024-03-24T22:10:12.235439",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.229495",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# **Convolutional Neural Networks(CNN)**\n",
    "CNNs,or convnets for short, are a special case of feedforward neural networks. They are very similar to the neural networks in the sense that they are made up of neurons with learnable weights and biases. The essential difference is that the CNN architecture makes the implicit assumption that the input are image-like, which allows us to encode certain properties in the architecture.\n",
    "\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://www.tomasbeuzen.com/deep-learning-with-pytorch/_images/cnn-6.png\" alt=\"neural network\">\n",
    "</div>\n",
    "\n",
    "# Why CNN?\n",
    "Full connectivity is a problem for image inputs<br>\n",
    "• Scalability: 200x200x3 images imply 120,000 weights per neuron in first\n",
    "hidden layer<br>\n",
    "• Overfitting: Too many parameters would lead to overfitting\n",
    "\n",
    "**Convolutional Neural Networks** are specialized to the case where inputs are images (more generally, data\n",
    "with a grid-like topology)<br>\n",
    "• Sparse connections, parameter sharing<br>\n",
    "• Efficient to train<br>\n",
    "• Avoid overfitting<br>\n",
    "• Generalize across spatial translations of input<br>\n",
    "• By sliding “filters” that learn distinct patterns (edges, blobs of color etc.)\n",
    "<br><br>\n",
    "**Key idea**<br>\n",
    "• Replace matrix multiplication in neural networks with convolution<br>\n",
    "• Everything else remains the same<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f453003",
   "metadata": {
    "papermill": {
     "duration": 0.005885,
     "end_time": "2024-03-24T22:10:12.247480",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.241595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# How Does CNN work?\n",
    "Before we go to the working of Convolutional neural networks (CNN), let’s cover the basics, such as what an image is and how it is represented. An RGB image is nothing but a matrix of pixel values having three planes whereas a grayscale image is the same but it has a single plane.\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://editor.analyticsvidhya.com/uploads/306461_15yDvGKV47a0nkf5qLKOOQ.png\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "For simplicity, let’s stick with grayscale images as we try to understand how CNNs work.\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://editor.analyticsvidhya.com/uploads/750710_QS1ArBEUJjjySXhE.png\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "We take a filter/kernel(3×3 matrix) and apply it to the input image to get the convolved feature. This convolved feature is passed on to the next layer.\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://editor.analyticsvidhya.com/uploads/419681_GcI7G-JLAQiEoCON7xFbhg.gif\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "# Filters on multiple channels\n",
    "Images are generally RGB !!<br>\n",
    "How would a filter work on a image\n",
    "with RGB channels?<br>\n",
    "The filter should also have 3\n",
    "channels.<br>\n",
    "Now the output has a channel for\n",
    "every filter we have used.<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6175374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T22:10:12.262023Z",
     "iopub.status.busy": "2024-03-24T22:10:12.261316Z",
     "iopub.status.idle": "2024-03-24T22:10:12.425173Z",
     "shell.execute_reply": "2024-03-24T22:10:12.423876Z"
    },
    "papermill": {
     "duration": 0.174117,
     "end_time": "2024-03-24T22:10:12.427878",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.253761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 70, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "images = load_sample_images()[\"images\"]\n",
    "\n",
    "# Center crop the images\n",
    "images = tf.keras.layers.CenterCrop(height=70,width=120)(images)  # Adjust central_fraction as needed\n",
    "\n",
    "# Rescale the pixel values to [0, 1]\n",
    "images = tf.keras.layers.Rescaling(scale=1/255)(images)\n",
    "\n",
    "labels = [0, 1] * (len(images) // 2)  # Assuming binary classification\n",
    "# Convert labels to arrays\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fa151",
   "metadata": {
    "papermill": {
     "duration": 0.006065,
     "end_time": "2024-03-24T22:10:12.440536",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.434471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ConvNet architecture\n",
    "• A ConvNet is made up of Layers<br>\n",
    "• Every Layer transforms an input 3D volume to an output 3D volume with\n",
    "some differentiable function that may or may not have parameters<br>\n",
    "• Neurons in a layer will only be connected to a small region of the layer\n",
    "before it\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vkQ0hXDaQv57sALXAJquxA.jpeg)\n",
    "\n",
    "Explaining the full architecture of a Convolutional Neural Network (ConvNet) can be quite extensive as there are various architectures with different depths and complexities. However, I'll provide a general overview of a typical ConvNet architecture, which may vary depending on the specific task and dataset.<br>\n",
    "\n",
    "Let's break down a simplified version of a ConvNet architecture:<br>\n",
    "\n",
    "1. Input Layer:<br>\n",
    "This is where the raw input data, usually an image, is fed into the network.<br>\n",
    "The input layer has dimensions corresponding to the size of the input image (e.g., width, height, and number of color channels).<br>\n",
    "\n",
    "2. Convolutional Layers:<br>\n",
    "Convolutional layers are the key building blocks of a ConvNet.<br>\n",
    "Each convolutional layer applies a set of learnable filters (kernels) to the input data.<br>\n",
    "These filters detect various features such as edges, textures, or patterns within the input image.<br>\n",
    "The output of each convolutional layer is a feature map, where each neuron represents the activation of a particular feature.<br>\n",
    "\n",
    "3. Activation Function:<br>\n",
    "Typically, an activation function such as ReLU (Rectified Linear Unit) follows each convolutional operation.<br>\n",
    "ReLU introduces non-linearity into the network, allowing it to learn complex patterns effectively.<br>\n",
    "\n",
    "4. Pooling Layers:<br>\n",
    "Pooling layers are used to reduce the spatial dimensions (width and height) of the feature maps while retaining important information.<br>\n",
    "Common pooling operations include max pooling or average pooling.<br>\n",
    "Pooling helps in making the representation smaller and more manageable, reducing the number of parameters and computation in the network.<br>\n",
    "\n",
    "4. Fully Connected Layers:<br>\n",
    "After several convolutional and pooling layers, the feature maps are flattened into a vector and fed into one or more fully connected layers.<br>\n",
    "Fully connected layers perform high-level reasoning on the extracted features.<br>\n",
    "These layers map the features to the output classes in classification tasks.<br>\n",
    "The final fully connected layer usually employs a softmax activation function for multi-class classification, producing class probabilities.<br>\n",
    "\n",
    "5. Output Layer:<br>\n",
    "The output layer provides the final predictions of the network.<br>\n",
    "For classification tasks, the output layer typically consists of neurons equal to the number of classes, with softmax activation to produce class probabilities.<br>\n",
    "For tasks like object detection or semantic segmentation, the output layer might have a different structure tailored to the specific requirements of the task.<br>\n",
    "\n",
    "6. Optional Layers:<br>\n",
    "Depending on the architecture and requirements, additional layers such as dropout layers for regularization, batch normalization layers for improved training stability, or skip connections for facilitating the training of deeper networks may be included.<br>\n",
    "\n",
    "![](https://analyticsindiamag.com/wp-content/uploads/2018/01/nural-network-05.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4610b5e",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.006238,
     "end_time": "2024-03-24T22:10:12.453070",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.446832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Convolution layers**\n",
    "\n",
    "This is the first building block of a CNN. As the name suggests, the main mathematical task performed is called convolution, which is the application of a sliding window function to a matrix of pixels representing an image. The sliding function applied to the matrix is called kernel or filter, and both can be used interchangeably.\n",
    "\n",
    "In the convolution layer, several filters of equal size are applied, and each filter is used to recognize a specific pattern from the image, such as the curving of the digits, the edges, the whole shape of the digits, and more.\n",
    "\n",
    "Put simply, in the convolution layer, we use small grids (called filters or kernels) that move over the image. Each small grid is like a mini magnifying glass that looks for specific patterns in the photo, like lines, curves, or shapes. As it moves across the photo, it creates a new grid that highlights where it found these patterns.\n",
    "\n",
    "For example, one filter might be good at finding straight lines, another might find curves, and so on. By using several different filters, the CNN can get a good idea of all the different patterns that make up the image.\n",
    "\n",
    "Let’s consider this 32x32 grayscale image of a handwritten digit. The values in the matrix are given for illustration purposes.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://images.datacamp.com/image/upload/v1700043954/image5_b9b4c3cb25.png\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Also, let’s consider the kernel used for the convolution. It is a matrix with a dimension of 3x3. The weights of each element of the kernel is represented in the grid. Zero weights are represented in the black grids and ones in the white grid.\n",
    "\n",
    "**Do we have to manually find these weights?**\n",
    "\n",
    "In real life, the weights of the kernels are determined during the training process of the neural network.\n",
    "\n",
    "Using these two matrices, we can perform the convolution operation by applying the dot product, and work as follows:\n",
    "\n",
    "1. Apply the kernel matrix from the top-left corner to the right.\n",
    "2. Perform element-wise multiplication.\n",
    "3. Sum the values of the products.\n",
    "4. The resulting value corresponds to the first value (top-left corner) in the convoluted matrix.\n",
    "5. Move the kernel down with respect to the size of the sliding window.\n",
    "\n",
    "Repeat steps 1 to 5 until the image matrix is fully covered.\n",
    "\n",
    "NOTE: The dimension of the convoluted matrix depends on the size of the sliding window. The higher the sliding window, the smaller the dimension.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://images.datacamp.com/image/upload/v1700043998/image9_fbc98b6c6e.png\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "# The Kernel\n",
    "\n",
    "We also have a feature detector, also known as a kernel or a filter, which will move across the receptive fields of the image, checking if the feature is present. This process is known as a convolution.\n",
    "\n",
    "The feature detector is a two-dimensional (2-D) array of weights, which represents part of the image. While they can vary in size, the filter size is typically a 3x3 matrix; this also determines the size of the receptive field. The filter is then applied to an area of the image, and a dot product is calculated between the input pixels and the filter. This dot product is then fed into an output array. Afterwards, the filter shifts by a stride, repeating the process until the kernel has swept across the entire image. The final output from the series of dot products from the input and the filter is known as a feature map, activation map, or a convolved feature.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:786/format:webp/1*GcI7G-JLAQiEoCON7xFbhg.gif\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Image Dimensions = 5 (Height) x 5 (Breadth) x 1 (Number of channels, eg. RGB)\n",
    "\n",
    "In the above demonstration, the green section resembles our 5x5x1 input image, I. The element involved in the convolution operation in the first part of a Convolutional Layer is called the Kernel/Filter, K, represented in color yellow. We have selected K as a 3x3x1 matrix.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://encrypted-tbn1.gstatic.com/images?q=tbn:ANd9GcTn9ZEVAqEutz1hbm01ZkZJVEr5g6mDDaIqeo-tIR8zfDJrYHts\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "The Kernel shifts 9 times because of Stride Length = 1 (Non-Strided), every time performing an elementwise multiplication operation (Hadamard Product) between K and the portion P of the image over which the kernel is hovering.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*NsiYxt8tPDQyjyH3C08PVA@2x.png\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "The filter moves to the right with a certain Stride Value till it parses the complete width. Moving on, it hops down to the beginning (left) of the image with the same Stride Value and repeats the process until the entire image is traversed.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*ciDgQEjViWLnCbmX-EeSrA.gif\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "In the case of images with multiple channels (e.g. RGB), the Kernel has the same depth as that of the input image. Matrix Multiplication is performed between Kn and In stack ([K1, I1]; [K2, I2]; [K3, I3]) and all the results are summed with the bias to give us a squashed one-depth channel Convoluted Feature Output.\n",
    "\n",
    "\n",
    "\n",
    "Note that the weights in the feature detector remain fixed as it moves across the image, which is also known as parameter sharing. Some parameters, like the weight values, adjust during training through the process of backpropagation and gradient descent. However, there are three hyperparameters which affect the volume size of the output that need to be set before the training of the neural network begins. These include:\n",
    "\n",
    "1. The number of filters affects the depth of the output. For example, three distinct filters would yield three different feature maps, creating a depth of three. \n",
    "\n",
    "2. Stride is the distance, or number of pixels, that the kernel moves over the input matrix. While stride values of two or greater is rare, a larger stride yields a smaller output.\n",
    "*  Step size with which we slide the filters\n",
    "*  When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 (or uncommonly 3 or more) then the filters jump 2 pixels at a time as we slide them around\n",
    "\n",
    "3. Zero-padding is usually used when the filters do not fit the input image. This sets all elements that fall outside of the input matrix to zero, producing a larger or equally sized output. There are three types of padding:\n",
    "\n",
    "* Valid padding: This is also known as no padding. In this case, the last convolution is dropped if dimensions do not align.\n",
    "* Same padding: This padding ensures that the output layer has the same size as the input layer.\n",
    "* Full padding: This type of padding increases the size of the output by adding zeros to the border of the input.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*nYf_cUIHFEWU1JXGwnz-Ig.gif\" alt=\"neural network\">\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "  SAME padding: 5x5x1 image is padded with 0s to create a 6x6x1 image\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "When we augment the 5x5x1 image into a 6x6x1 image and then apply the 3x3x1 kernel over it, we find that the convolved matrix turns out to be of dimensions 5x5x1. Hence the name — Same Padding.\n",
    "\n",
    "On the other hand, if we perform the same operation without padding, we are presented with a matrix that has dimensions of the Kernel (3x3x1) itself — Valid Padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb2603d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T22:10:12.468176Z",
     "iopub.status.busy": "2024-03-24T22:10:12.467330Z",
     "iopub.status.idle": "2024-03-24T22:10:12.574673Z",
     "shell.execute_reply": "2024-03-24T22:10:12.573846Z"
    },
    "papermill": {
     "duration": 0.117385,
     "end_time": "2024-03-24T22:10:12.576894",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.459509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64, 114, 32)\n"
     ]
    }
   ],
   "source": [
    "conv_layer=tf.keras.layers.Conv2D(filters=32,kernel_size=7)\n",
    "#the default option is named padding=\"valid\" which means no zero padding at all \n",
    "fmaps=conv_layer(images)\n",
    "print(fmaps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c0f403d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T22:10:12.592722Z",
     "iopub.status.busy": "2024-03-24T22:10:12.591960Z",
     "iopub.status.idle": "2024-03-24T22:10:12.614002Z",
     "shell.execute_reply": "2024-03-24T22:10:12.612620Z"
    },
    "papermill": {
     "duration": 0.033092,
     "end_time": "2024-03-24T22:10:12.616877",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.583785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 70, 120, 32)\n"
     ]
    }
   ],
   "source": [
    "'''if we set padding=\"same\" instead,then the inputs are padded with enough zeroes on all sides to \n",
    "ensure the output feature maps end up with the same size as input'''\n",
    "\n",
    "conv_layer=tf.keras.layers.Conv2D(filters=32,kernel_size=7,padding=\"same\")\n",
    "fmaps=conv_layer(images)\n",
    "print(fmaps.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a29f7c7",
   "metadata": {
    "papermill": {
     "duration": 0.006363,
     "end_time": "2024-03-24T22:10:12.630030",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.623667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Pooling layer**\n",
    "\n",
    "Similar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial size of the Convolved Feature. This is to decrease the computational power required to process the data through dimensionality reduction. Furthermore, it is useful for extracting dominant features which are rotational and positional invariant, thus maintaining the process of effectively training the model.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*uoWYsCV5vBU8SHFPAPao-w.gif\" alt=\"neural network\">\n",
    "</div>\n",
    "\n",
    "The goal of the pooling layer is to pull the most significant features from the convoluted matrix. This is done by applying some aggregation operations, which reduce the dimension of the feature map (convoluted matrix), hence reducing the memory used while training the network. Pooling is also relevant for mitigating overfitting.\n",
    "\n",
    "The most common aggregation functions that can be applied are:\n",
    "\n",
    "* Max pooling, which is the maximum value of the feature map\n",
    "* Sum pooling corresponds to the sum of all the values of the feature map\n",
    "* Average pooling is the average of all the values.\n",
    "\n",
    "Max Pooling also performs as a Noise Suppressant. It discards the noisy activations altogether and also performs de-noising along with dimensionality reduction. On the other hand, Average Pooling simply performs dimensionality reduction as a noise-suppressing mechanism. Hence, we can say that Max Pooling performs a lot better than Average Pooling.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*KQIEqhxzICU7thjaQBfPBQ.png\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "The Convolutional Layer and the Pooling Layer, together form the i-th layer of a Convolutional Neural Network. Depending on the complexities in the images, the number of such layers may be increased for capturing low-level details even further, but at the cost of more computational power.\n",
    "\n",
    "After going through the above process, we have successfully enabled the model to understand the features. Moving on, we are going to flatten the final output and feed it to a regular Neural Network for classification purposes.\n",
    "\n",
    "Also, the dimension of the feature map becomes smaller as the pooling function is applied.\n",
    "\n",
    "The last pooling layer flattens its feature map so that it can be processed by the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7a6904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T22:10:12.645061Z",
     "iopub.status.busy": "2024-03-24T22:10:12.644626Z",
     "iopub.status.idle": "2024-03-24T22:10:12.660494Z",
     "shell.execute_reply": "2024-03-24T22:10:12.659596Z"
    },
    "papermill": {
     "duration": 0.026752,
     "end_time": "2024-03-24T22:10:12.663410",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.636658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.4901961  0.54901963 0.5686275 ]\n",
      "   [0.3647059  0.47450984 0.4784314 ]\n",
      "   [0.24705884 0.39607847 0.3529412 ]\n",
      "   ...\n",
      "   [0.90196085 0.8980393  0.9176471 ]\n",
      "   [0.9058824  0.90196085 0.9215687 ]\n",
      "   [0.9058824  0.9058824  0.9215687 ]]\n",
      "\n",
      "  [[0.48627454 0.4039216  0.46274513]\n",
      "   [0.26666668 0.27058825 0.28627452]\n",
      "   [0.43137258 0.5137255  0.49411768]\n",
      "   ...\n",
      "   [0.90196085 0.90196085 0.909804  ]\n",
      "   [0.90196085 0.90196085 0.909804  ]\n",
      "   [0.9058824  0.9058824  0.91372555]]\n",
      "\n",
      "  [[0.32156864 0.30588236 0.23137257]\n",
      "   [0.3254902  0.29803923 0.19607845]\n",
      "   [0.36078432 0.30980393 0.27450982]\n",
      "   ...\n",
      "   [0.90196085 0.90196085 0.909804  ]\n",
      "   [0.90196085 0.90196085 0.909804  ]\n",
      "   [0.9058824  0.9058824  0.91372555]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5137255  0.25490198 0.19215688]\n",
      "   [0.4666667  0.33333334 0.227451  ]\n",
      "   [0.53333336 0.34117648 0.18823531]\n",
      "   ...\n",
      "   [0.7686275  0.81568635 0.8196079 ]\n",
      "   [0.77647066 0.8196079  0.82745105]\n",
      "   [0.7686275  0.8117648  0.8196079 ]]\n",
      "\n",
      "  [[0.33333334 0.30588236 0.26666668]\n",
      "   [0.3803922  0.32941177 0.2627451 ]\n",
      "   [0.4039216  0.33333334 0.26666668]\n",
      "   ...\n",
      "   [0.7686275  0.81568635 0.81568635]\n",
      "   [0.7686275  0.8078432  0.8117648 ]\n",
      "   [0.7843138  0.81568635 0.8235295 ]]\n",
      "\n",
      "  [[0.4431373  0.4666667  0.4666667 ]\n",
      "   [0.5058824  0.44705886 0.33333334]\n",
      "   [0.45882356 0.43529415 0.3921569 ]\n",
      "   ...\n",
      "   [0.7843138  0.8235295  0.8196079 ]\n",
      "   [0.7843138  0.8235295  0.8196079 ]\n",
      "   [0.7843138  0.8196079  0.81568635]]]\n",
      "\n",
      "\n",
      " [[[0.87843144 0.42352945 0.15686275]\n",
      "   [0.86274517 0.4431373  0.16862746]\n",
      "   [0.882353   0.50980395 0.24705884]\n",
      "   ...\n",
      "   [0.9490197  0.5529412  0.29803923]\n",
      "   [0.9568628  0.5529412  0.2901961 ]\n",
      "   [0.9490197  0.6039216  0.3372549 ]]\n",
      "\n",
      "  [[0.82745105 0.3529412  0.03529412]\n",
      "   [0.86666673 0.3529412  0.00784314]\n",
      "   [0.83921576 0.32941177 0.04705883]\n",
      "   ...\n",
      "   [0.93725497 0.67058825 0.48627454]\n",
      "   [0.93725497 0.6901961  0.49411768]\n",
      "   [0.9333334  0.6509804  0.47058827]]\n",
      "\n",
      "  [[0.85098046 0.27450982 0.01176471]\n",
      "   [0.8196079  0.2627451  0.02352941]\n",
      "   [0.8470589  0.23137257 0.02352941]\n",
      "   ...\n",
      "   [0.89019614 0.6117647  0.40000004]\n",
      "   [0.8862746  0.6745098  0.42352945]\n",
      "   [0.8980393  0.68235296 0.45882356]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.9176471  0.5176471  0.23529413]\n",
      "   [0.909804   0.4666667  0.19215688]\n",
      "   [0.85098046 0.4039216  0.11764707]\n",
      "   ...\n",
      "   [0.89019614 0.427451   0.18431373]\n",
      "   [0.8313726  0.3647059  0.05490196]\n",
      "   [0.85098046 0.39607847 0.09411766]]\n",
      "\n",
      "  [[0.97647065 0.5686275  0.2901961 ]\n",
      "   [0.9215687  0.54509807 0.24705884]\n",
      "   [0.8980393  0.45882356 0.13725491]\n",
      "   ...\n",
      "   [0.94117653 0.50980395 0.27450982]\n",
      "   [0.86274517 0.38431376 0.12156864]\n",
      "   [0.8588236  0.43921572 0.14117648]]\n",
      "\n",
      "  [[0.9803922  0.5686275  0.3372549 ]\n",
      "   [0.9725491  0.5294118  0.26666668]\n",
      "   [0.9450981  0.50980395 0.23137257]\n",
      "   ...\n",
      "   [0.9058824  0.5294118  0.3019608 ]\n",
      "   [0.95294124 0.5803922  0.32941177]\n",
      "   [0.882353   0.43529415 0.14901961]]]], shape=(2, 35, 60, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#implementing pooling layers with keras \n",
    "max_pool= tf.keras.layers.MaxPool2D(pool_size=2)\n",
    "print(max_pool(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a15bff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T22:10:12.679649Z",
     "iopub.status.busy": "2024-03-24T22:10:12.678667Z",
     "iopub.status.idle": "2024-03-24T22:10:12.692464Z",
     "shell.execute_reply": "2024-03-24T22:10:12.691294Z"
    },
    "papermill": {
     "duration": 0.024483,
     "end_time": "2024-03-24T22:10:12.695112",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.670629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.64338624 0.5971759  0.5824972 ]\n",
      " [0.76306933 0.2601113  0.10849128]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
    "output = global_avg_pool(images)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2266d7",
   "metadata": {
    "papermill": {
     "duration": 0.006606,
     "end_time": "2024-03-24T22:10:12.708580",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.701974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Fully connected layers**\n",
    "\n",
    "These layers are in the last layer of the convolutional neural network, and their inputs correspond to the flattened one-dimensional matrix generated by the last pooling layer. ReLU activations functions are applied to them for non-linearity.\n",
    "\n",
    "The name of the full-connected layer aptly describes itself. As mentioned earlier, the pixel values of the input image are not directly connected to the output layer in partially connected layers. However, in the fully-connected layer, each node in the output layer connects directly to a node in the previous layer.\n",
    "\n",
    "Adding a Fully-Connected layer is a (usually) cheap way of learning non-linear combinations of the high-level features as represented by the output of the convolutional layer. The Fully-Connected layer is learning a possibly non-linear function in that space.\n",
    "\n",
    "Finally, a softmax prediction layer is used to generate probability values for each of the possible output labels, and the final label predicted is the one with the highest probability score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e42074d",
   "metadata": {
    "papermill": {
     "duration": 0.006573,
     "end_time": "2024-03-24T22:10:12.722183",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.715610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Activation Function**\n",
    "\n",
    "Activation functions play a crucial role in Convolutional Neural Networks (CNNs) by introducing non-linearity into the network, allowing it to learn complex patterns and relationships within the data. Here's an explanation of some commonly used activation functions in CNNs:\n",
    "\n",
    "**1. ReLU (Rectified Linear Unit):**\n",
    "* f(x)=max(0,x)\n",
    "* ReLU is the most widely used activation function in CNNs due to its simplicity and effectiveness.\n",
    "* It introduces non-linearity by outputting zero for negative input values and leaving positive values unchanged.\n",
    "* Benefits include faster convergence during training and alleviation of the vanishing gradient problem.\n",
    "* However, ReLU can suffer from the \"dying ReLU\" problem where neurons can become inactive (output zero) indefinitely during training if the weighted sum of inputs is consistently negative.\n",
    "\n",
    "**2. Sigmoid Function:**\n",
    "* Sigmoid squashes input values to the range [0, 1].\n",
    "* Historically used in neural networks for binary classification tasks where the output needs to be interpreted as probabilities.\n",
    "* However, it suffers from vanishing gradient and is rarely used in hidden layers of deep neural networks due to its saturation property, which leads to the vanishing gradient problem.\n",
    "\n",
    "**3. Tanh (Hyperbolic Tangent):**\n",
    "* Tanh squashes input values to the range [-1, 1].\n",
    "* Similar to the sigmoid function but centered around zero, which allows it to model negative values.\n",
    "* Like sigmoid, tanh also suffers from vanishing gradient, particularly for deep networks.\n",
    "\n",
    "**4. Leaky ReLU:**\n",
    "* Leaky ReLU addresses the dying ReLU problem by allowing a small gradient when the input is negative (typically, alpha is a small constant, e.g., 0.01).\n",
    "* This function helps to mitigate the issues with ReLU while maintaining its benefits of fast convergence.\n",
    "\n",
    "**5. Softmax:**\n",
    "* Softmax is commonly used in the output layer of CNNs for multi-class classification tasks.\n",
    "* It normalizes the output into a probability distribution over multiple classes, ensuring that the sum of the output probabilities equals one.\n",
    "* Softmax is useful when the network needs to make mutually exclusive predictions across multiple classes.\n",
    "\n",
    "**6. ELU (Exponential Linear Unit):**\n",
    "* ELU, like Leaky ReLU, also tries to alleviate the dying ReLU problem and can push mean unit activations closer to zero, which speeds up learning.\n",
    "\n",
    "These activation functions contribute to the non-linear mapping of inputs to outputs in CNNs, enabling them to learn complex representations of data and perform effectively in various tasks such as image classification, object detection, and segmentation. Choosing the appropriate activation function depends on the specific characteristics of the problem at hand and empirical performance on the dataset.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://media.licdn.com/dms/image/C4E12AQFqIFCj71YJPw/article-cover_image-shrink_600_2000/0/1620764635917?e=2147483647&v=beta&t=E6iCHNUyncJu9QUjCX4EmVLgQanUw_WS6KnWrlV4Roc\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f83bcb",
   "metadata": {
    "papermill": {
     "duration": 0.007308,
     "end_time": "2024-03-24T22:10:12.736337",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.729029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Overfitting and Regularization in CNNs**\n",
    "Overfitting is a common challenge in machine learning models and CNN deep learning projects. It happens when the model learns the training data too well (“learning by heart”), including its noise and outliers. Such a learning leads to a model that performs well on the training data but badly on new, unseen data.\n",
    "\n",
    "This can be observed when the performance on training data is too low compared to the performance on validation or testing data, and a graphical illustration is given below:\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"https://images.datacamp.com/image/upload/v1700044100/image3_93b1b7c0d9.png\" alt=\"neural network\">\n",
    "</div>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a18c4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T22:10:12.752028Z",
     "iopub.status.busy": "2024-03-24T22:10:12.751636Z",
     "iopub.status.idle": "2024-03-24T22:10:12.924260Z",
     "shell.execute_reply": "2024-03-24T22:10:12.923333Z"
    },
    "papermill": {
     "duration": 0.202934,
     "end_time": "2024-03-24T22:10:12.946102",
     "exception": false,
     "start_time": "2024-03-24T22:10:12.743168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                102464    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122506 (478.54 KB)\n",
      "Trainable params: 122506 (478.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Here is how we can implement a basic CNN \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the input shape (e.g., image dimensions)\n",
    "input_shape = (28, 28, 3)  # Example input shape for an RGB image with size 28x28\n",
    "\n",
    "num_classes=10\n",
    "# Initialize a Sequential model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add the first convolutional layer\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "# Explanation:\n",
    "# - Conv2D: This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.\n",
    "# - 32: Number of filters/kernels to use.\n",
    "# - (3, 3): Size of the convolutional window.\n",
    "# - 'relu': Activation function (Rectified Linear Unit).\n",
    "# - input_shape: Shape of input data.\n",
    "\n",
    "# Add a max pooling layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Explanation:\n",
    "# - MaxPooling2D: This layer downsamples the input along its spatial dimensions (height and width) using max pooling.\n",
    "# - (2, 2): Pooling window size.\n",
    "\n",
    "# Add another convolutional layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# Explanation: Same as the first convolutional layer but with 64 filters.\n",
    "\n",
    "# Add another max pooling layer\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the output to feed into fully connected layers\n",
    "model.add(layers.Flatten())\n",
    "# Explanation: This layer flattens the input, transforming it into a 1D array.\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Explanation:\n",
    "# - Dense: Fully connected layer.\n",
    "# - 64: Number of neurons in the layer.\n",
    "# - 'relu': Activation function.\n",
    "\n",
    "# Add a dropout layer for regularization\n",
    "model.add(layers.Dropout(0.5))\n",
    "# Explanation: Dropout is a regularization technique where a random fraction of input units are dropped out (set to zero) during training.\n",
    "\n",
    "# Add the output layer\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "# Explanation:\n",
    "# - Dense: Fully connected output layer.\n",
    "# - num_classes: Number of classes in the classification task.\n",
    "# - 'softmax': Activation function for multi-class classification, producing class probabilities.\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Explanation:\n",
    "# - Optimizer: Algorithm used for optimizing the network weights (e.g., Adam).\n",
    "# - Loss: Loss function used for training the model (e.g., categorical_crossentropy for multi-class classification).\n",
    "# - Metrics: Evaluation metrics to be monitored during training (e.g., accuracy).\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.712805,
   "end_time": "2024-03-24T22:10:14.592435",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-24T22:09:51.879630",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
